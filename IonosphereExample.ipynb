{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irace2 import irace, dummy_stats_test\n",
    "from sampling_functions import norm_sample, truncated_poisson, truncated_skellam\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import statsmodels.stats.weightstats as stats\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,cross_val_score\n",
    "from scipy.stats import norm, poisson, skellam\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spect_train.csv')\n",
    "X = preprocessing.normalize(df.drop(columns=['OVERALL_DIAGNOSIS']).to_numpy())\n",
    "y = df['OVERALL_DIAGNOSIS'].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the parameters being configures must be set beforehand\n",
    "models = [LogisticRegression(C=1), \n",
    "    RandomForestClassifier(n_estimators=100,max_depth=5,ccp_alpha=0.0),\n",
    "    SVC(C=1,coef0=0.0),\n",
    "    XGBClassifier(n_estimators=100,max_depth=6,subsample=1)]\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    'LogisticRegression': {'C': lambda loc : norm_sample(loc=loc, scale=1, min= 1e-2),\n",
    "                            'penalty':['l2'],\n",
    "                            'solver':['lbfgs','newton-cg','sag']},\n",
    "    'SVC':{'C':lambda loc : norm_sample(loc=loc, scale=1, min= 1e-2),\n",
    "            'coef0': lambda loc : norm_sample(loc=loc, scale=1, min= 1e-2),\n",
    "            'kernel':['linear','poly','rbf','sigmoid'],\n",
    "            'decision_function_shape':['ovo','ovr']},\n",
    "    'RandomForestClassifier': {'n_estimators': lambda loc: truncated_skellam(loc, mu1=10, mu2=10, min=1), \n",
    "                                'max_depth': lambda loc: truncated_skellam(loc, mu1=1, mu2=1, min=1),\n",
    "                                'max_features':['sqrt', 'log2', None],\n",
    "                                'ccp_alpha':lambda loc : norm_sample(loc=loc, scale=0.1, min= 1e-3)\n",
    "                                },\n",
    "    'XGBClassifier': {'sample_type': ['uniform','weighted'], \n",
    "                        'max_depth': lambda loc: truncated_skellam(loc, mu1=1, mu2=1, min=1),\n",
    "                        'booster':['gbtree','dart'],\n",
    "                        'subsample':lambda loc : norm_sample(loc=loc, scale=0.3, min= 1e-2,max=1)}\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0\n",
      "\n",
      "Average scores: 0.7005761309264343\n",
      "Gen 1\n",
      "\n",
      "Average scores: 0.7342370903143949\n",
      "Gen 2\n",
      "\n",
      "Average scores: 0.7406184277654254\n",
      "Gen 3\n",
      "\n",
      "Average scores: 0.742060751025905\n",
      "Gen 4\n",
      "\n",
      "Average scores: 0.7459508314503202\n",
      "Gen 5\n",
      "\n",
      "Average scores: 0.7459508314503202\n",
      "Gen 6\n",
      "\n",
      "Average scores: 0.7473225588339446\n",
      "Gen 7\n",
      "\n",
      "Average scores: 0.7473225588339446\n",
      "Gen 8\n",
      "\n",
      "Average scores: 0.7473225588339446\n",
      "Gen 9\n",
      "\n",
      "Average scores: 0.7473225588339446\n",
      "Gen 10\n",
      "\n",
      "Average scores: 0.7502946157530602\n",
      "Gen 11\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 12\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 13\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 14\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 15\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 16\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 17\n",
      "\n",
      "Average scores: 0.7524366904870787\n",
      "Gen 18\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 19\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 20\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 21\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 22\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 23\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 24\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 25\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 26\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 27\n",
      "\n",
      "Average scores: 0.7552156244561916\n",
      "Gen 28\n",
      "\n",
      "Average scores: 0.7574014531550062\n",
      "Gen 29\n",
      "\n",
      "Average scores: 0.7574014531550062\n",
      "Gen 30\n",
      "\n",
      "Average scores: 0.7574014531550062\n",
      "Gen 31\n",
      "\n",
      "Average scores: 0.7574014531550062\n",
      "Gen 32\n",
      "\n",
      "Average scores: 0.7574014531550062\n",
      "Gen 33\n",
      "\n",
      "Average scores: 0.7574014531550062\n",
      "Gen 34\n",
      "\n",
      "Average scores: 0.7588489819044614\n",
      "Gen 35\n",
      "\n",
      "Average scores: 0.7605332018596689\n",
      "Gen 36\n",
      "\n",
      "Average scores: 0.7605332018596689\n",
      "Gen 37\n",
      "\n",
      "Average scores: 0.7605332018596689\n",
      "Gen 38\n",
      "\n",
      "Average scores: 0.7605332018596689\n",
      "Gen 39\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 40\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 41\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 42\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 43\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 44\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 45\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 46\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 47\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 48\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 49\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 50\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 51\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 52\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 53\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 54\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 55\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 56\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 57\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 58\n",
      "\n",
      "Average scores: 0.7627133267135796\n",
      "Gen 59\n",
      "\n",
      "Average scores: 0.7653187596215745\n",
      "Gen 60\n",
      "\n",
      "Average scores: 0.7653187596215745\n",
      "Gen 61\n",
      "\n",
      "Average scores: 0.7653187596215745\n",
      "Gen 62\n",
      "\n",
      "Average scores: 0.7653187596215745\n",
      "Gen 63\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 64\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 65\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 66\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 67\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 68\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 69\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 70\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 71\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 72\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 73\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 74\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 75\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 76\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 77\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 78\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 79\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 80\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 81\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 82\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 83\n",
      "\n",
      "Average scores: 0.7671733554360086\n",
      "Gen 84\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 85\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 86\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 87\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 88\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 89\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 90\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 91\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 92\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 93\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 94\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 95\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 96\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 97\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: 0.7702946848746642\n",
      "Gen 99\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 100\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 101\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 102\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 103\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 104\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 105\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 106\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 107\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 108\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 109\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 110\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 111\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 112\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 113\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 114\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 115\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 116\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 117\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 118\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 119\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 120\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 121\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 122\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 123\n",
      "\n",
      "Average scores: 0.7702946848746642\n",
      "Gen 124\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 125\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 126\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 127\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: 0.7723658571485782\n",
      "Gen 129\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 130\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 131\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 132\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 133\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 134\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 135\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 136\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 137\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 138\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 139\n",
      "\n",
      "Average scores: 0.7723658571485782\n",
      "Gen 140\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 141\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 142\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 143\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 144\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 145\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 146\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 147\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 148\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 149\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 150\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 151\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 152\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 153\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 154\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 155\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 156\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 157\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 158\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 159\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 160\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 161\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 162\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 163\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 164\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 165\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 166\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 167\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 168\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 169\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 170\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 171\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 172\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 173\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 174\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 175\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 176\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 177\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 178\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 179\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 180\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 181\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 182\n",
      "\n",
      "Average scores: 0.7749264633088769\n",
      "Gen 183\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 184\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 185\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 186\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 187\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 188\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 189\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 190\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 191\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 192\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 193\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 194\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 195\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 196\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 197\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 198\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 199\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 200\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 201\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 202\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 203\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 204\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 205\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 206\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 207\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 208\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 209\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 210\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 211\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: 0.776911864784654\n",
      "Gen 213\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 214\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 215\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 216\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 217\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 218\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 219\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 220\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 221\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 222\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 223\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 224\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 225\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 226\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 227\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 228\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 229\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 230\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 231\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 232\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 233\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 234\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 235\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 236\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 237\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 238\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 239\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 240\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 241\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 242\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 243\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 244\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 245\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 246\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 247\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 248\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 249\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 250\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 251\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 252\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 253\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 254\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 255\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 256\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 257\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 258\n",
      "\n",
      "Average scores: 0.776911864784654\n",
      "Gen 259\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 260\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 261\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 262\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 263\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 264\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: 0.7786821387027495\n",
      "Gen 265\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 266\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 267\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 268\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 269\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 270\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 271\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 272\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 273\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 274\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 275\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 276\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 277\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 278\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 279\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 280\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 281\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 282\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 283\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 284\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 285\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 286\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 287\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 288\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 289\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 290\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 291\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 292\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 293\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 294\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 295\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 296\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 297\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 298\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 299\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 300\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 301\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 302\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 303\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 304\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 305\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 306\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 307\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 308\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 309\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 310\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 311\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 312\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 313\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 314\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 315\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 316\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 317\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 318\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 319\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 320\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 321\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 322\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 323\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 324\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 325\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 326\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 327\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 328\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 329\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 330\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 331\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 332\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 333\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 334\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 335\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 336\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 337\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 338\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 339\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 340\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 341\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 342\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 343\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 344\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 345\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 346\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 347\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 348\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 349\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 350\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 351\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 352\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 353\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 354\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 355\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 356\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 357\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 358\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 359\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 360\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 361\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 362\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 363\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 364\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 365\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 366\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 367\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 368\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 369\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 370\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 371\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 372\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 373\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 374\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 375\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 376\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 377\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 378\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 379\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 380\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 381\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 382\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 383\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 384\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 385\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 386\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 387\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 388\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 389\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 390\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 391\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 392\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 393\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 394\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 395\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 396\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 397\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 398\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 399\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 400\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 401\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 402\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 403\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 404\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 405\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 406\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 407\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 408\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: 0.7786821387027495\n",
      "Gen 410\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 411\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 412\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 413\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 414\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 415\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 416\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 417\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 418\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 419\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 420\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 421\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 422\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 423\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 424\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 425\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 426\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 427\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 428\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 429\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 430\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 431\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 432\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 433\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 434\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 435\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 436\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 437\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 438\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 439\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 440\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 441\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 442\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 443\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 444\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 445\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 446\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 447\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 448\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 449\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 450\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 451\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 452\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 453\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 454\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 455\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 456\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 457\n",
      "\n",
      "Average scores: 0.7786821387027495\n",
      "Gen 458\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m stat_tests \u001b[39m=\u001b[39m [ ss\u001b[39m.\u001b[39mttest_rel,\n\u001b[0;32m      2\u001b[0m                 ss\u001b[39m.\u001b[39mttest_ind,\n\u001b[0;32m      3\u001b[0m                 ss\u001b[39m.\u001b[39mmannwhitneyu,\n\u001b[0;32m      4\u001b[0m                 ss\u001b[39m.\u001b[39mwilcoxon,\n\u001b[0;32m      5\u001b[0m                 dummy_stats_test] \n\u001b[0;32m      7\u001b[0m stat_test \u001b[39m=\u001b[39m ss\u001b[39m.\u001b[39mmannwhitneyu \u001b[39m#stats.ttest_ind, stats.mannwhitneyu\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m best_model,best_scores,pop, pop_scores \u001b[39m=\u001b[39m irace(models, X, y, \u001b[39mlambda\u001b[39;49;00m x: x \u001b[39m>\u001b[39;49m \u001b[39m500\u001b[39;49m, stat_test, parameters_dict, pop_size \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1_macro\u001b[39;49m\u001b[39m'\u001b[39;49m, r\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\source\\repos\\StatisticalTestsForMachineLearningModels\\irace2.py:52\u001b[0m, in \u001b[0;36mirace\u001b[1;34m(models, X, y, stop_condition, stat_test, parameters_dict, pop_size, scoring, cv, r)\u001b[0m\n\u001b[0;32m     50\u001b[0m     scores \u001b[39m=\u001b[39m cross_val_score(competitor, X, y, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     scores \u001b[39m=\u001b[39m repeated_train_test(competitor, X, y, n\u001b[39m=\u001b[39;49mr, scoring\u001b[39m=\u001b[39;49mscoring)\n\u001b[0;32m     54\u001b[0m t, p \u001b[39m=\u001b[39m stat_test(pop_scores[i], scores) \n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mmean(scores) \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mmean(pop_scores[i]):  \n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\source\\repos\\StatisticalTestsForMachineLearningModels\\validation_functions.py:13\u001b[0m, in \u001b[0;36mrepeated_train_test\u001b[1;34m(model, X, y, n, scoring)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m     10\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     11\u001b[0m         X, y, test_size\u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand()\u001b[39m*\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     14\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     16\u001b[0m     scores\u001b[39m.\u001b[39mappend(scorer\u001b[39m.\u001b[39m_score_func(y_test,y_pred))\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:178\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 178\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state)\n\u001b[0;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m    181\u001b[0m         \u001b[39m# Need to validate separately here.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m         \u001b[39m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[0;32m    183\u001b[0m         \u001b[39m# csr.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rcpsi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1226\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m   1224\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmtrand\u001b[39m.\u001b[39m_rand\n\u001b[0;32m   1225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(seed, numbers\u001b[39m.\u001b[39mIntegral):\n\u001b[1;32m-> 1226\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mRandomState(seed)\n\u001b[0;32m   1227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(seed, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState):\n\u001b[0;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m seed\n",
      "File \u001b[1;32mmtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mt19937.pyx:129\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mbit_generator.pyx:519\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.BitGenerator.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mbit_generator.pyx:309\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mbit_generator.pyx:394\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.get_assembled_entropy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stat_tests = [ ss.ttest_rel,\n",
    "                ss.ttest_ind,\n",
    "                ss.mannwhitneyu,\n",
    "                ss.wilcoxon,\n",
    "                dummy_stats_test] \n",
    "\n",
    "stat_test = ss.mannwhitneyu #stats.ttest_ind, stats.mannwhitneyu\n",
    "\n",
    "best_model,best_scores,pop, pop_scores = irace(models, X, y, lambda x: x > 500, stat_test, parameters_dict, pop_size = 30, scoring='f1_macro', r=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "for i in range(len(pop)):\n",
    "    print(pop[i])\n",
    "    scores = cross_val_score(pop[i], X, y, cv=10, scoring='f1') \n",
    "    print(f'{np.mean(scores)} +- {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "for i in range(len(pop)):\n",
    "    print(pop[i]) \n",
    "    print(f'{np.mean(pop_scores[i])} +- {np.std(pop_scores[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=======================================')\n",
    "print(best_model)\n",
    "print(f'{np.mean(best_scores)}+-{np.std(best_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(SVC(), X, y, cv=10, scoring='f1')\n",
    "print(f'{np.mean(scores)} +- {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "738f0abc388fde32d91a23dc48b434080bb97b14dd548d1e86272d1e373043ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
